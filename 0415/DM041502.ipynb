{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from Imbalanced Data\n",
    "<br><img align=\"left\" src=\"http://drive.google.com/uc?export=view&id=1DzKZ9ufrjHd9JtsoSvy8ayCsib54FFgr\" width=800 height=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches\n",
    "- **Sampling**\n",
    "  - Random Undersampling\n",
    "  - Random Oversampling\n",
    "  - SMOTE\n",
    "  - Tomek Links\n",
    "  - SMOTE + Tomek Links\n",
    "  - Using GAN(Generative Adversarial Networks)\n",
    "- **Algorithms**\n",
    "  - Cost-sensitive learning methods\n",
    "  - Kernel-based methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling heuristics\n",
    "- Consider testing under-sampling when you have an a lot data (tens- or hundreds of thousands of instances or more)\n",
    "- Consider testing over-sampling when you don’t have a lot of data (tens of thousands of records or less)\n",
    "- Consider testing random and non-random (e.g. stratified) sampling schemes.\n",
    "- Consider testing different resampled ratios (e.g. you don’t have to target a 1:1 ratio in a binary classification problem, try other ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced-learn\n",
    "- imbalanced data 문제를 해결하기 위한 다양한 샘플링 방법을 구현한 파이썬 패키지\n",
    "- 설치방법: `pip install -U imbalanced-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X00, y00 = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0, \n",
    "                               n_classes=2, n_clusters_per_class=1, class_sep=0.8, \n",
    "                               weights=[0.99, 0.01], random_state=0)\n",
    "X0, X_test, y0, y_test = train_test_split(X00, y00, test_size=0.25, random_state=12345)\n",
    "\n",
    "x1_min = X00[:, 0].min() - 2\n",
    "x1_max = X00[:, 0].max() + 2\n",
    "x2_min = X00[:, 1].min() - 2\n",
    "x2_max = X00[:, 1].max() + 2\n",
    "\n",
    "def plot_samples(X=None, y=None):\n",
    "    XX, YY = np.mgrid[x1_min:x1_max:300j, x2_min:x2_max:300j]\n",
    "    params = {'kernel': 'linear'}\n",
    "#    params = {'kernel': 'rbf', 'gamma': 1}\n",
    "    if X is None:\n",
    "        plt.figure(figsize=(7,7))\n",
    "        X = X0\n",
    "        model = SVC(**params).fit(X0, y0)\n",
    "        Z = model.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "        Z = Z.reshape(XX.shape)\n",
    "        plt.contourf(XX, YY, Z, alpha=0.6)\n",
    "        plt.scatter(X0[:, 0], X0[:, 1], marker='o', c=y0, s=40, \n",
    "                    linewidth=1, edgecolor='gray', alpha=0.7)\n",
    "        plt.title(Counter(y0))\n",
    "    else:\n",
    "        plt.figure(figsize=(14,7))\n",
    "        plt.subplot(121)\n",
    "        model = SVC(**params).fit(X0, y0)\n",
    "        Z = model.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "        Z = Z.reshape(XX.shape)\n",
    "        plt.contourf(XX, YY, Z, alpha=0.6)\n",
    "        plt.scatter(X0[:, 0], X0[:, 1], marker='o', c=y0, s=40, \n",
    "                    linewidth=1, edgecolor='gray', alpha=0.7)\n",
    "        plt.xlim(-2, 4)\n",
    "        plt.ylim(-3, 4)\n",
    "        plt.title(Counter(y0))\n",
    "        plt.subplot(122)\n",
    "        model = SVC(**params).fit(X, y)\n",
    "        Z = model.predict(np.c_[XX.ravel(), YY.ravel()])\n",
    "        Z = Z.reshape(XX.shape)\n",
    "        plt.contourf(XX, YY, Z, alpha=0.6)\n",
    "        plt.scatter(X[:, 0], X[:, 1], marker='o', c=y, s=40, \n",
    "                    linewidth=1, edgecolor='gray', alpha=0.7)\n",
    "        plt.xlim(-2, 4)\n",
    "        plt.ylim(-3, 4)\n",
    "        plt.title(Counter(y))\n",
    "        plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model.predict(X)\n",
    "    \n",
    "y_pred = plot_samples()\n",
    "print(classification_report(y0, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"#CC3D3D\">\n",
    "### SMOTE: an over-sampling class method\n",
    "<br><img align=\"left\" src=\"http://drive.google.com/uc?export=view&id=1K_oqSphPKgP7uWsjjbp9Gs6jEbYwzuzt\" width=400 height=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import *\n",
    "\n",
    "X, y = SMOTE(random_state=0,k_neighbors=5).fit_sample(X0, y0)\n",
    "y_pred = plot_samples(X, y)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"#CC3D3D\">\n",
    "### Tomek links: a under-sampling class method\n",
    "<br><img align=\"left\" src=\"http://drive.google.com/uc?export=view&id=1ZbHsYSK1_SjXPM-rxgWy3PB2a1I-sfEz\" width=500 height=300>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import *\n",
    "\n",
    "X, y = TomekLinks(random_state=0, sampling_strategy='all').fit_sample(X0, y0)\n",
    "y_pred = plot_samples(X, y)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"#CC3D3D\">\n",
    "### SMOTE + Tomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import *\n",
    "\n",
    "X, y = SMOTETomek(random_state=0, sampling_strategy='all').fit_sample(X0, y0)\n",
    "y_pred = plot_samples(X, y)\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced data 생성\n",
    "digits = load_digits()\n",
    "y = digits.target == 9  # 숫자 9를 posive class로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/평가 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE + Tomek 방법으로 합성데이터 추가\n",
    "sm = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = sm.fit_sample(X_train, y_train)\n",
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래 데이터를 사용했을 때의 모델성능\n",
    "y_pred = RandomForestClassifier(random_state=0).fit(X_train, y_train).predict(X_test)\n",
    "accuracy_score(y_test, y_pred), roc_auc_score(y_test, y_pred), f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성 데이터를 추가했을 때의 모델성능\n",
    "y_pred = RandomForestClassifier(random_state=0).fit(X_resampled, y_resampled).predict(X_test)\n",
    "accuracy_score(y_test, y_pred), roc_auc_score(y_test, y_pred), f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced learning 방법을 변경해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification 알고리즘을 변경해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalance의 정도를 바꿔보자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
